{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-11T02:35:03.841912Z",
     "start_time": "2025-08-11T02:34:54.365214Z"
    }
   },
   "source": [
    "# %% Copy keypoint CSVs grouped by (PD_or_C, turning_angle, type_of_turn)\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ===== CONFIG (your exact paths) =====\n",
    "FEATURES_CSV = r\"D:\\Courses\\thesis\\data\\21h9f9e30v9cl2fapjggz4q1x7\\Turning\\Data\\cleaned_turning_project_2d_features.csv\"\n",
    "BASE_TURNING_DIR = r\"D:\\Courses\\thesis\\data\\21h9f9e30v9cl2fapjggz4q1x7\\Turning\\Data\\turning_2D3D_skeletons_coarsened\\Turning_coarsen_CSV\"\n",
    "OUTPUT_DIR = r\"D:\\Courses\\thesis\\data\\turning_keypoints_grouped\"\n",
    "\n",
    "# ===== Expected columns in FEATURES_CSV =====\n",
    "COL_TURN_ID = \"Turn ID\"\n",
    "COL_SUBJ_ID = \"Participant ID number\"\n",
    "COL_PD_OR_C = \"PD_or_C\"\n",
    "COL_ANGLE   = \"turning_angle\"\n",
    "COL_TURNTYP = \"type_of_turn\"\n",
    "\n",
    "# --- Load features table ---\n",
    "df = pd.read_csv(FEATURES_CSV)\n",
    "\n",
    "# Basic checks\n",
    "for col in [COL_TURN_ID, COL_SUBJ_ID, COL_PD_OR_C, COL_ANGLE, COL_TURNTYP]:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' not found in {FEATURES_CSV}\")\n",
    "\n",
    "# Keep only needed columns and drop rows missing essentials\n",
    "df = df[[COL_TURN_ID, COL_SUBJ_ID, COL_PD_OR_C, COL_ANGLE, COL_TURNTYP]].dropna(subset=[COL_TURN_ID, COL_SUBJ_ID, COL_PD_OR_C])\n",
    "\n",
    "# Normalize strings\n",
    "norm = lambda x: str(x).strip()\n",
    "df[COL_PD_OR_C] = df[COL_PD_OR_C].map(norm)\n",
    "df[COL_ANGLE]   = df[COL_ANGLE].map(norm)\n",
    "df[COL_TURNTYP] = df[COL_TURNTYP].map(norm)\n",
    "\n",
    "# Safe int cast for IDs used in folder names\n",
    "def to_int_safe(x):\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df[\"__turn_id_int\"] = df[COL_TURN_ID].apply(to_int_safe)\n",
    "df[\"__subj_id_int\"] = df[COL_SUBJ_ID].apply(to_int_safe)\n",
    "\n",
    "# Build folder: Pt{ID}_{PD_or_C}_n_{turn_id}\n",
    "def make_folder_name(row):\n",
    "    pid = row[\"__subj_id_int\"]\n",
    "    tid = row[\"__turn_id_int\"]\n",
    "    lab = row[COL_PD_OR_C]\n",
    "    if pid is None or tid is None or not lab:\n",
    "        return None\n",
    "    return f\"Pt{pid}_{lab}_n_{tid}\"\n",
    "\n",
    "df[\"__folder\"] = df.apply(make_folder_name, axis=1)\n",
    "df_valid = df.dropna(subset=[\"__folder\"]).copy()\n",
    "\n",
    "BASE_TURNING_DIR = Path(BASE_TURNING_DIR)\n",
    "OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "copied, missing = [], []\n",
    "\n",
    "def safe(s: str) -> str:\n",
    "    s = str(s)\n",
    "    for ch in r'<>:\"/\\|?*':\n",
    "        s = s.replace(ch, \"_\")\n",
    "    return s.strip() or \"UNK\"\n",
    "\n",
    "for _, row in df_valid.iterrows():\n",
    "    folder = row[\"__folder\"]\n",
    "    src = BASE_TURNING_DIR / folder / \"input_2D\" / \"keypoints.csv\"\n",
    "\n",
    "    pd_or_c = row[COL_PD_OR_C] or \"UNK\"\n",
    "    angle   = row[COL_ANGLE]   or \"UNK\"\n",
    "    ttype   = row[COL_TURNTYP] or \"UNK\"\n",
    "\n",
    "    dst_dir = OUTPUT_DIR / safe(pd_or_c) / safe(angle) / safe(ttype)\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dst = dst_dir / f\"{folder}.csv\"\n",
    "\n",
    "    if src.exists():\n",
    "        try:\n",
    "            shutil.copy2(src, dst)\n",
    "            copied.append({\n",
    "                \"folder\": folder, \"src\": str(src), \"dst\": str(dst),\n",
    "                COL_PD_OR_C: pd_or_c, COL_ANGLE: angle, COL_TURNTYP: ttype,\n",
    "                COL_SUBJ_ID: row[COL_SUBJ_ID], COL_TURN_ID: row[COL_TURN_ID],\n",
    "            })\n",
    "        except Exception as e:\n",
    "            missing.append({\n",
    "                \"folder\": folder, \"src\": str(src), \"reason\": f\"copy_error: {e}\",\n",
    "                COL_PD_OR_C: pd_or_c, COL_ANGLE: angle, COL_TURNTYP: ttype,\n",
    "                COL_SUBJ_ID: row[COL_SUBJ_ID], COL_TURN_ID: row[COL_TURN_ID],\n",
    "            })\n",
    "    else:\n",
    "        missing.append({\n",
    "            \"folder\": folder, \"src\": str(src), \"reason\": \"not_found\",\n",
    "            COL_PD_OR_C: pd_or_c, COL_ANGLE: angle, COL_TURNTYP: ttype,\n",
    "            COL_SUBJ_ID: row[COL_SUBJ_ID], COL_TURN_ID: row[COL_TURN_ID],\n",
    "        })\n",
    "\n",
    "# Save manifests for audit\n",
    "copied_df = pd.DataFrame(copied)\n",
    "missing_df = pd.DataFrame(missing)\n",
    "copied_csv  = OUTPUT_DIR / \"_manifest_copied.csv\"\n",
    "missing_csv = OUTPUT_DIR / \"_manifest_missing.csv\"\n",
    "copied_df.to_csv(copied_csv, index=False)\n",
    "missing_df.to_csv(missing_csv, index=False)\n",
    "\n",
    "print(f\"Done. Copied: {len(copied)} | Missing: {len(missing)}\")\n",
    "print(f\"Copied manifest : {copied_csv}\")\n",
    "print(f\"Missing manifest: {missing_csv}\")\n",
    "\n",
    "if not copied_df.empty:\n",
    "    print(\"\\nTop groups by count:\")\n",
    "    print(copied_df.groupby([COL_PD_OR_C, COL_ANGLE, COL_TURNTYP]).size().sort_values(ascending=False).head(20))\n",
    "else:\n",
    "    print(\"\\nNo files copied. Double-check paths and that folder names match 'Pt<ID>_<PD/C>_n_<turnID>'.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Copied: 1681 | Missing: 0\n",
      "Copied manifest : D:\\Courses\\thesis\\data\\turning_keypoints_grouped\\_manifest_copied.csv\n",
      "Missing manifest: D:\\Courses\\thesis\\data\\turning_keypoints_grouped\\_manifest_missing.csv\n",
      "\n",
      "Top groups by count:\n",
      "PD_or_C  turning_angle  type_of_turn\n",
      "PD       90_degrees     pivot_turn      404\n",
      "C        90_degrees     pivot_turn      392\n",
      "         180_degrees    pivot_turn      234\n",
      "PD       180_degrees    pivot_turn      209\n",
      "         135_degrees    pivot_turn       97\n",
      "         90_degrees     step_turn        90\n",
      "         180_degrees    step_turn        76\n",
      "C        135_degrees    pivot_turn       74\n",
      "PD       135_degrees    step_turn        33\n",
      "         90_degrees     -                18\n",
      "C        90_degrees     step_turn        13\n",
      "         180_degrees    step_turn        12\n",
      "         90_degrees     -                10\n",
      "PD       135_degrees    -                 4\n",
      "         180_degrees    -                 4\n",
      "C        225_degrees    pivot_turn        3\n",
      "         135_degrees    step_turn         3\n",
      "PD       225_degrees    step_turn         2\n",
      "C        135_degrees    -                 1\n",
      "         360_degrees    pivot_turn        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
